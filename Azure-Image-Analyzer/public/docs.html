<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>API Documentation - Azure Image Analyzer</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/themes/prism-tomorrow.min.css">
</head>
<body class="bg-gray-100 min-h-screen">
    <nav class="bg-white shadow-lg">
        <div class="max-w-6xl mx-auto px-4">
            <div class="flex justify-between items-center py-4">
                <a href="/" class="text-2xl font-bold text-gray-800">Azure Image Analyzer</a>
                <div class="space-x-4">
                    <a href="/upload" class="text-gray-600 hover:text-gray-900">Upload Image</a>
                    <a href="/camera" class="text-gray-600 hover:text-gray-900">Use Camera</a>
                </div>
            </div>
        </div>
    </nav>

    <main class="max-w-4xl mx-auto px-4 py-8">
        <div class="bg-white rounded-lg shadow-lg p-6">
            <h1 class="text-3xl font-bold text-gray-900 mb-6">API Documentation</h1>

            <div class="prose max-w-none">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Overview</h2>
                <p class="text-gray-600 mb-6">
                    The Azure Image Analyzer API allows you to analyze images using Azure OpenAI's GPT-4 Vision model.
                    You can upload images or capture them using your device's camera, and get detailed analysis of the content.
                </p>

                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Authentication</h2>
                <p class="text-gray-600 mb-6">
                    The API requires Azure OpenAI credentials to be set in the environment variables:
                </p>
                <pre class="bg-gray-800 text-white p-4 rounded-lg mb-6"><code>AZURE_OPENAI_KEY=your_key_here
AZURE_OPENAI_ENDPOINT=your_endpoint_here
AZURE_OPENAI_API_VERSION=2024-12-01-preview</code></pre>

                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Endpoints</h2>

                <div class="mb-8">
                    <h3 class="text-xl font-semibold text-gray-800 mb-2">Analyze Image</h3>
                    <p class="text-gray-600 mb-4">Analyzes an image using Azure OpenAI's GPT-4 Vision model.</p>
                    
                    <div class="bg-gray-50 p-4 rounded-lg mb-4">
                        <p class="font-mono text-sm mb-2">POST /analyze-image</p>
                        <p class="text-gray-600 mb-4">Content-Type: application/json</p>
                        
                        <h4 class="font-semibold text-gray-800 mb-2">Request Body:</h4>
                        <pre class="bg-gray-800 text-white p-4 rounded-lg mb-4"><code>{
    "base64Image": "string", // Base64 encoded image
    "prompt": "string"       // Optional custom prompt
}</code></pre>

                        <h4 class="font-semibold text-gray-800 mb-2">Response:</h4>
                        <pre class="bg-gray-800 text-white p-4 rounded-lg"><code>{
    "response": "string",    // Analysis result
    "usage": {              // Token usage information
        "total_tokens": number
    }
}</code></pre>
                    </div>
                </div>

                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Example Usage</h2>
                <div class="bg-gray-50 p-4 rounded-lg mb-6">
                    <h3 class="font-semibold text-gray-800 mb-2">JavaScript Example:</h3>
                    <pre class="bg-gray-800 text-white p-4 rounded-lg"><code>const analyzeImage = async (base64Image, prompt = 'Describe this image') => {
    const response = await fetch('/analyze-image', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            base64Image,
            prompt
        })
    });
    
    const data = await response.json();
    return data;
};</code></pre>
                </div>

                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Error Handling</h2>
                <div class="bg-gray-50 p-4 rounded-lg">
                    <p class="text-gray-600 mb-4">The API returns appropriate HTTP status codes and error messages:</p>
                    <ul class="list-disc list-inside text-gray-600">
                        <li>400 Bad Request - Invalid input (e.g., missing image)</li>
                        <li>500 Internal Server Error - Server-side error</li>
                    </ul>
                </div>
            </div>
        </div>
    </main>

    <footer class="bg-gray-800 text-white mt-12">
        <div class="max-w-6xl mx-auto px-4 py-8">
            <div class="text-center">
                <p>Powered by Azure OpenAI GPT-4 Vision X Teal</p>
                <p class="mt-2 text-gray-400">Â© 2025 AiCraftersX Teal Text Summarization API. All rights reserved</p>
            </div>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-json.min.js"></script>
</body>
</html> 